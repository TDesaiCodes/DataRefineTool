# -*- coding: utf-8 -*-
"""Welcome to Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import pandas as pd
import numpy as np

file_path = "cust.csv"
df = pd.read_csv("/cust.csv")

print(" Initial Dataset Info ") #loading data set
print("Rows, Columns:", df.shape)
print("Missing values:\n", df.isnull().sum())
print("Duplicate rows:", df.duplicated().sum())
print("-------\n")

for col in df.columns:   #handling missing values
    if df[col].dtype in ['int64', 'float64']:
        df[col].fillna(df[col].median(), inplace=True)
    else:
        df[col].fillna(df[col].mode()[0], inplace=True)

duplicates = df.duplicated().sum()  #removing duplicates
df = df.drop_duplicates()
print("Duplicates removed:", duplicates)

numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns #Outlier detection using IQR

Q1 = df[numeric_cols].quantile(0.25)
Q3 = df[numeric_cols].quantile(0.75)
IQR = Q3 - Q1

df = df[~((df[numeric_cols] < (Q1 - 1.5 * IQR)) | (df[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]

print("Outliers removed using IQR method.")

print("Data Statistics:\n", df.describe()) #statistics

df = pd.get_dummies(df, drop_first=True) #converting text categories into numbers

print("\n=== Cleaned Dataset Info ===")  #summary
print("Rows, Columns:", df.shape)
print("Missing values:\n", df.isnull().sum().sum())
print("Duplicate rows:", df.duplicated().sum())
print("\n=== Basic Statistics ===")
print(df.describe())

df.to_csv("cleaned_data.csv", index=False)

from google.colab import files
files.download("cleaned_data.csv")

!jupyter nbconvert --to script /content/Notebook.ipynb

df.to_csv("cleaned_data.csv.gz", index=False, compression="gzip")

from google.colab import files
files.download("cleaned_data.csv.gz")